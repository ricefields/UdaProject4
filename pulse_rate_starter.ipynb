{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Pulse Rate Algorithm\n",
    "\n",
    "### Contents\n",
    "Fill out this notebook as part of your final project submission.\n",
    "\n",
    "**You will have to complete both the Code and Project Write-up sections.**\n",
    "- The [Code](#Code) is where you will write a **pulse rate algorithm** and already includes the starter code.\n",
    "   - Imports - These are the imports needed for Part 1 of the final project. \n",
    "     - [glob](https://docs.python.org/3/library/glob.html)\n",
    "     - [numpy](https://numpy.org/)\n",
    "     - [scipy](https://www.scipy.org/)\n",
    "- The [Project Write-up](#Project-Write-up) to describe why you wrote the algorithm for the specific case.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "You will be using the **Troika**[1] dataset to build your algorithm. Find the dataset under `datasets/troika/training_data`. The `README` in that folder will tell you how to interpret the data. The starter code contains a function to help load these files.\n",
    "\n",
    "1. Zhilin Zhang, Zhouyue Pi, Benyuan Liu, ‘‘TROIKA: A General Framework for Heart Rate Monitoring Using Wrist-Type Photoplethysmographic Signals During Intensive Physical Exercise,’’IEEE Trans. on Biomedical Engineering, vol. 62, no. 2, pp. 522-531, February 2015. Link\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io\n",
    "from scipy import io, signal\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "fs      = 125  # All signals were sampled at 125 HZ\n",
    "min_freq= 0.67 # Corresponding to 40 BPM\n",
    "max_freq= 4.0  # Corresponding to ~200 BPM\n",
    "\n",
    "def LoadTroikaDataset():\n",
    "    \"\"\"\n",
    "    Retrieve the .mat filenames for the troika dataset.\n",
    "\n",
    "    Review the README in ./datasets/troika/ to understand the organization of the .mat files.\n",
    "\n",
    "    Returns:\n",
    "        data_fls: Names of the .mat files that contain signal data\n",
    "        ref_fls: Names of the .mat files that contain reference data\n",
    "        <data_fls> and <ref_fls> are ordered correspondingly, so that ref_fls[5] is the \n",
    "            reference data for data_fls[5], etc...\n",
    "    \"\"\"\n",
    "    data_dir = \"./datasets/troika/training_data\"\n",
    "    data_fls = sorted(glob.glob(data_dir + \"/DATA_*.mat\"))\n",
    "    ref_fls  = sorted(glob.glob(data_dir + \"/REF_*.mat\"))\n",
    "    return data_fls, ref_fls\n",
    "\n",
    "def LoadTroikaDataFile(data_fl):\n",
    "    \"\"\"\n",
    "    Loads and extracts signals from a troika data file.\n",
    "\n",
    "    Usage:\n",
    "        data_fls, ref_fls = LoadTroikaDataset()\n",
    "        ppg, accx, accy, accz = LoadTroikaDataFile(data_fls[0])\n",
    "\n",
    "    Args:\n",
    "        data_fl: (str) filepath to a troika .mat file.\n",
    "\n",
    "    Returns:\n",
    "        numpy arrays for ppg, accx, accy, accz signals.\n",
    "    \"\"\"\n",
    "    data = sp.io.loadmat(data_fl)['sig']\n",
    "    data\n",
    "    return data[2:]\n",
    "\n",
    "def AggregateErrorMetric(pr_errors, confidence_est):\n",
    "    \"\"\"\n",
    "    Computes an aggregate error metric based on confidence estimates.\n",
    "\n",
    "    Computes the MAE at 90% availability. \n",
    "\n",
    "    Args:\n",
    "        pr_errors: a numpy array of errors between pulse rate estimates and corresponding \n",
    "            reference heart rates.\n",
    "        confidence_est: a numpy array of confidence estimates for each pulse rate\n",
    "            error.\n",
    "\n",
    "    Returns:\n",
    "        the MAE at 90% availability\n",
    "    \"\"\"\n",
    "    # Higher confidence means a better estimate. The best 90% of the estimates\n",
    "    # are above the 10th percentile confidence.\n",
    "    percentile90_confidence = np.percentile(confidence_est, 10)\n",
    "\n",
    "    # Find the errors of the best pulse rate estimates\n",
    "    best_estimates = pr_errors[confidence_est >= percentile90_confidence]\n",
    "    \n",
    "    # Return the mean absolute error\n",
    "    return np.mean(np.abs(best_estimates))\n",
    "\n",
    "def PassFilter(signal, passband):\n",
    "    \"\"\"\n",
    "    Filter out frequencies of the signal that are outside of the passband\n",
    "    Args:\n",
    "        signal: The signal to be processed\n",
    "        bandpass: The permissible frequency band\n",
    "    Returns:\n",
    "        The filtered signal\n",
    "    \"\"\"\n",
    "    b, a = sp.signal.butter(3, passband, btype='bandpass', fs=fs)\n",
    "    return sp.signal.filtfilt(b, a, signal)\n",
    "\n",
    "def Evaluate():\n",
    "    \"\"\"\n",
    "    Top-level function evaluation function.\n",
    "\n",
    "    Runs the pulse rate algorithm on the Troika dataset and returns an aggregate error metric.\n",
    "\n",
    "    Returns:\n",
    "        Pulse rate error on the Troika dataset. See AggregateErrorMetric.\n",
    "    \"\"\"\n",
    "    # Retrieve dataset files\n",
    "    data_fls, ref_fls = LoadTroikaDataset()\n",
    "    errs, confs = [], []\n",
    "    for data_fl, ref_fl in zip(data_fls, ref_fls):\n",
    "        # Run the pulse rate algorithm on each trial in the dataset\n",
    "        errors, confidence = RunPulseRateAlgorithm(data_fl, ref_fl)\n",
    "        errs.append(errors)\n",
    "        confs.append(confidence)\n",
    "   \n",
    "    # Compute aggregate error metric\n",
    "    errs  = np.hstack(errs)\n",
    "    confs = np.hstack(confs)\n",
    "    return AggregateErrorMetric(errs, confs)\n",
    "\n",
    "\n",
    "def RunPulseRateAlgorithm(data_fl, ref_fl): \n",
    "    \"\"\" Calculates mean absolute errors and confidence values\n",
    "    \n",
    "    Args: \n",
    "        data_fl: (str) filepath to a troika .mat file.\n",
    "        ref_f1: (str) filepath to a troika .mat file which contains reference heart beat estimates.\n",
    "        \n",
    "    Returns:\n",
    "        error_array: Array of absolute errors\n",
    "        conf_array: Array of confidence values for each error value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    ppg, accx, accy, accz = LoadTroikaDataFile(data_fl)\n",
    "    \n",
    "    ground_truth = sp.io.loadmat(ref_fl)['BPM0']    \n",
    "    # Convert into a 1D array\n",
    "    ground_truth = ground_truth.reshape(-1)\n",
    "    \n",
    "    # Band pass ppg and acc signals \n",
    "    bandpassed_ppg = PassFilter(ppg, (min_freq, max_freq))\n",
    "    \n",
    "    # Splits of 8-second windows with 6-second overlaps since ground truth slides every 2 seconds\n",
    "    spec_ppg, freqs_ppg, _  = mlab.specgram(bandpassed_ppg, Fs=fs, NFFT=fs*8, noverlap = 6*fs, pad_to=12*fs)\n",
    "    # plt.xlabel('Time')\n",
    "    # plt.ylabel('Frequency')\n",
    "    # plt.title(\"Bandpass filtered PPG signal\")\n",
    "    accx = PassFilter(accx, (min_freq, max_freq))\n",
    "    accy = PassFilter(accy, (min_freq, max_freq))\n",
    "    accz = PassFilter(accz, (min_freq, max_freq))\n",
    "\n",
    "    bandpassed_acc_mag = np.sqrt(np.sum(np.square(np.vstack((accx, accy, accz))), axis=0))\n",
    "    \n",
    "    # Specgram of the band-passed time-domain signals\n",
    "    spec_acc, freqs_acc, _    = mlab.specgram(bandpassed_acc_mag, Fs=fs, NFFT=fs*8, noverlap = 6*fs, pad_to=12*fs)\n",
    "    spec_accx, freqs_accx, _  = mlab.specgram(accx, Fs=fs, NFFT=fs*8, noverlap = 6*fs, pad_to=12*fs)\n",
    "    spec_accy, freqs_accy, _  = mlab.specgram(accy, Fs=fs, NFFT=fs*8, noverlap = 6*fs, pad_to=12*fs)\n",
    "    spec_accz, freqs_accz, _  = mlab.specgram(accz, Fs=fs, NFFT=fs*8, noverlap = 6*fs, pad_to=12*fs)\n",
    "\n",
    "    # Corresponding to (and before) applying the band pass on the frequencies that makes physiological \n",
    "    # sense (see code block below this), we have to \"sanitize\" the spectrum array \n",
    "    # So the number of rows (spec_ppg.shape[0]) will become shorter. The number of columns will remain the\n",
    "    # same, corresponding to the number of time blocks\n",
    "    spec_ppg  = spec_ppg [(freqs_ppg   >= min_freq) & (freqs_ppg <= max_freq)]\n",
    "    spec_acc  = spec_acc [(freqs_acc   >= min_freq) & (freqs_acc <= max_freq)]\n",
    "    spec_accx = spec_accx [(freqs_accx >= min_freq) & (freqs_accx <= max_freq)]\n",
    "    spec_accy = spec_accy [(freqs_accy >= min_freq) & (freqs_accy <= max_freq)]\n",
    "    spec_accz = spec_accz [(freqs_accz >= min_freq) & (freqs_accz <= max_freq)]\n",
    "    \n",
    "    # Pass through a frequency band that makes physiological sense.\n",
    "    # This reduces the number of frequencies\n",
    "    freqs_ppg  = freqs_ppg [(freqs_ppg   >= min_freq) & (freqs_ppg <= max_freq)]\n",
    "    freqs_acc  = freqs_acc [(freqs_acc   >= min_freq) & (freqs_acc <= max_freq)]\n",
    "    freqs_accx = freqs_accx [(freqs_accx >= min_freq) & (freqs_accx <= max_freq)]\n",
    "    freqs_accy = freqs_accy [(freqs_accy >= min_freq) & (freqs_accy <= max_freq)]\n",
    "    freqs_accz = freqs_accz [(freqs_accz >= min_freq) & (freqs_accz <= max_freq)]\n",
    "\n",
    "    \n",
    "    # spec_ppg is a 2D array. The COLUMNS correspond to each time block. The rows within each column correspond to \n",
    "    # frequency values\n",
    "    num_time_blocks = spec_ppg.shape[1]\n",
    "    num_frequencies = freqs_ppg.shape[0]\n",
    "    #print (\"num=\", num_time_blocks)\n",
    "    \n",
    "    # Sort in descending order, so -1*spec\n",
    "    # Each row corresponds to one time block\n",
    "    sorted_spectrum_ppg  = (-spec_ppg).argsort(axis=0)\n",
    "    sorted_spectrum_acc  = (-spec_acc).argsort(axis=0)\n",
    "    sorted_spectrum_accx = (-spec_accx).argsort(axis=0)\n",
    "    sorted_spectrum_accy = (-spec_accy).argsort(axis=0)\n",
    "    sorted_spectrum_accz = (-spec_accz).argsort(axis=0)\n",
    "\n",
    "    predicted_freqs = []\n",
    "    for i in range(num_time_blocks):\n",
    "        flag = 0\n",
    "        \n",
    "        # Check if dominant frequency in PPG overlaps with the top-3 peaks in ACCX, ACCY, ACCZ\n",
    "        # and ACC_MAGNITUDE\n",
    "        if (freqs_ppg[sorted_spectrum_ppg[0][i]]   == freqs_accx[sorted_spectrum_accx[0][i]]):\n",
    "            flag = 1\n",
    "        elif (freqs_ppg[sorted_spectrum_ppg[0][i]] == freqs_accy[sorted_spectrum_accy[0][i]]):\n",
    "            flag = 1\n",
    "        elif (freqs_ppg[sorted_spectrum_ppg[0][i]] == freqs_accz[sorted_spectrum_accz[0][i]]):\n",
    "            flag = 1\n",
    "        elif (freqs_ppg[sorted_spectrum_ppg[0][i]] == freqs_acc[sorted_spectrum_acc[0][i]]):\n",
    "            flag = 1\n",
    "        elif (freqs_ppg[sorted_spectrum_ppg[0][i]] == freqs_accx[sorted_spectrum_accx[1][i]]):\n",
    "            flag = 1\n",
    "        elif (freqs_ppg[sorted_spectrum_ppg[0][i]] == freqs_accy[sorted_spectrum_accy[1][i]]):\n",
    "            flag = 1\n",
    "        elif (freqs_ppg[sorted_spectrum_ppg[0][i]] == freqs_accz[sorted_spectrum_accz[1][i]]):\n",
    "            flag = 1\n",
    "        elif (freqs_ppg[sorted_spectrum_ppg[0][i]] == freqs_acc[sorted_spectrum_acc[1][i]]):\n",
    "            flag = 1\n",
    "        elif (freqs_ppg[sorted_spectrum_ppg[0][i]] == freqs_accx[sorted_spectrum_accx[2][i]]):\n",
    "            flag = 1\n",
    "        elif (freqs_ppg[sorted_spectrum_ppg[0][i]] == freqs_accy[sorted_spectrum_accy[2][i]]):\n",
    "            flag = 1\n",
    "        elif (freqs_ppg[sorted_spectrum_ppg[0][i]] == freqs_accz[sorted_spectrum_accz[2][i]]):\n",
    "            flag = 1\n",
    "        elif (freqs_ppg[sorted_spectrum_ppg[0][i]] == freqs_acc[sorted_spectrum_acc[2][i]]):\n",
    "            flag = 1\n",
    "        else:\n",
    "            #print (\"Dominant Freq Chosen as Heart Rate\")\n",
    "            predicted_freqs.append (freqs_ppg[sorted_spectrum_ppg[0][i]])\n",
    "        \n",
    "        # Check if second dominant frequency in PPG overlaps with the top-3 peaks in ACCX, ACCY, ACCZ\n",
    "        # and ACC_MAGNITUDE\n",
    "        if (flag):         \n",
    "            flag = 0\n",
    "            if (freqs_ppg[sorted_spectrum_ppg[1][i]] == freqs_accx[sorted_spectrum_accx[0][i]]):\n",
    "                 flag = 1\n",
    "            elif (freqs_ppg[sorted_spectrum_ppg[1][i]] == freqs_accy[sorted_spectrum_accy[0][i]]):\n",
    "                 flag = 1\n",
    "            elif (freqs_ppg[sorted_spectrum_ppg[1][i]] == freqs_accz[sorted_spectrum_accz[0][i]]):\n",
    "                 flag = 1   \n",
    "            elif (freqs_ppg[sorted_spectrum_ppg[1][i]] == freqs_acc[sorted_spectrum_acc[0][i]]):\n",
    "                 flag = 1   \n",
    "            elif (freqs_ppg[sorted_spectrum_ppg[1][i]] == freqs_accx[sorted_spectrum_accx[1][i]]):\n",
    "                 flag = 1\n",
    "            elif (freqs_ppg[sorted_spectrum_ppg[1][i]] == freqs_accy[sorted_spectrum_accy[1][i]]):\n",
    "                 flag = 1\n",
    "            elif (freqs_ppg[sorted_spectrum_ppg[1][i]] == freqs_accz[sorted_spectrum_accz[1][i]]):\n",
    "                 flag = 1 \n",
    "            elif (freqs_ppg[sorted_spectrum_ppg[1][i]] == freqs_acc[sorted_spectrum_acc[1][i]]):\n",
    "                 flag = 1 \n",
    "            elif (freqs_ppg[sorted_spectrum_ppg[1][i]] == freqs_accx[sorted_spectrum_accx[2][i]]):\n",
    "                 flag = 1\n",
    "            elif (freqs_ppg[sorted_spectrum_ppg[1][i]] == freqs_accy[sorted_spectrum_accy[2][i]]):\n",
    "                 flag = 1\n",
    "            elif (freqs_ppg[sorted_spectrum_ppg[1][i]] == freqs_accz[sorted_spectrum_accz[2][i]]):\n",
    "                 flag = 1   \n",
    "            elif (freqs_ppg[sorted_spectrum_ppg[1][i]] == freqs_acc[sorted_spectrum_acc[2][i]]):\n",
    "                 flag = 1 \n",
    "                \n",
    "            if (flag):\n",
    "                #print (\"Second Dominant Freq Chosen as Heart Rate\")\n",
    "                predicted_freqs.append (freqs_ppg[sorted_spectrum_ppg[2][i]]) \n",
    "            else:\n",
    "                #print (\"Third Dominant Freq Chosen as Heart Rate\")\n",
    "                predicted_freqs.append (freqs_ppg[sorted_spectrum_ppg[1][i]])   \n",
    "\n",
    "    predicted_freqs_array = np.array(predicted_freqs)*60\n",
    "    #print (\"Lengths=\", len(predicted_freqs_array), len(ground_truth))\n",
    "    #print (\"Pred BPM =\", predicted_freqs_array, \"Ground Truth =\", ground_truth)\n",
    "    #plt.clf()\n",
    "    #plt.figure(0)\n",
    "    #plt.title('Predictions vs Ground Truth')\n",
    "    #plt.plot (predicted_freqs_array)\n",
    "    #plt.plot (ground_truth)\n",
    "    error = np.abs(predicted_freqs_array - ground_truth)\n",
    "    \n",
    "    confidence_list = []\n",
    "    i = 0\n",
    "    for i in range(len(predicted_freqs)):\n",
    "        pred = predicted_freqs[i]\n",
    "    \n",
    "        # Convert to frequency domain to parition the area\n",
    "        # surrounding the signal and the rest of the signal\n",
    "        freqs = np.fft.rfftfreq(len(bandpassed_ppg)*2, 1/fs)\n",
    "        fft_mag = np.abs(np.fft.rfft(bandpassed_ppg, len(bandpassed_ppg)*2))\n",
    "\n",
    "        # Definition of surrounding = Width of the window size\n",
    "        window_slice = 0.20  # Try 0.2 HZ\n",
    "        fwindow_size = (freqs > pred - window_slice) & (freqs < pred + window_slice)\n",
    "        \n",
    "        # Signal\n",
    "        sig = np.sum(fft_mag[(fwindow_size)])\n",
    "        \n",
    "        # Noise\n",
    "        noi = np.sum(fft_mag[~(fwindow_size)])\n",
    "\n",
    "        snr_ratio = sig/noi \n",
    "        confidence_list.append(snr_ratio)\n",
    "\n",
    "    confidence = np.array(confidence_list)\n",
    "\n",
    "    return error, confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting..\n",
      "Error = 20.1164103933\n"
     ]
    }
   ],
   "source": [
    "print (\"Starting..\")\n",
    "error = Evaluate()\n",
    "print (\"Error =\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Project Write-up\n",
    "\n",
    "Answer the following prompts to demonstrate understanding of the algorithm you wrote for this specific context.\n",
    "\n",
    "> - **Code Description** - Include details so someone unfamiliar with your project will know how to run your code and use your algorithm. \n",
    "> - **Data Description** - Describe the dataset that was used to train and test the algorithm. Include its short-comings and what data would be required to build a more complete dataset.\n",
    "> - **Algorithhm Description** will include the following:\n",
    ">   - how the algorithm works\n",
    ">   - the specific aspects of the physiology that it takes advantage of\n",
    ">   - a describtion of the algorithm outputs\n",
    ">   - caveats on algorithm outputs \n",
    ">   - common failure modes\n",
    "> - **Algorithm Performance** - Detail how performance was computed (eg. using cross-validation or train-test split) and what metrics were optimized for. Include error metrics that would be relevant to users of your algorithm. Caveat your performance numbers by acknowledging how generalizable they may or may not be on different datasets.\n",
    "\n",
    "Your write-up goes here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis project seeks to determine the heart rate from PPG signals captured from a wearable and corroborate/tune \\nresults with the help of data elicited from an accelerometer. \\n\\nThe algorithm slices each PPG dataset into chunks of 2-seconds and slides that window until the end of the signal\\nFor each slice, it performs transformation into frequency domain using Fourier Transforms. It then attenuates it using\\na band pass filter by cancelling out frequencies outside of 0.67 HZ (corresponding to 40 BPM) and \\n4 HZ (corresponding ot 240 BPM) It then finds out the peaks in the signal. We check that the distance between \\npeaks in the time domain roughly corresponds to the highest frequency \\ncomponent in the frequency domain.\\n\\nIt then computes the L2 Norm of the accelerometer signals after passing the components through the same band pass\\nfilter as alluded to above. \\n\\nIf the highest peak in the PPG signal is near to a peak in the accelerometer signal, the next non-overlapping peak\\nin the PPG signal is chosen.\\n\\nError components are then calculated to reach a degree of confidence in the results.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This project seeks to determine the heart rate from PPG signals captured from a wearable and corroborate/tune \n",
    "results with the help of data elicited from an accelerometer. \n",
    "\n",
    "- All signals are tuned using a bandpass filter to cancel frequencies outside of 0.67 HZ40 BPM) and 3.3 HZ (200 BPM). \n",
    "  Please see observation 6/ below.\n",
    "- The algorithm then slices each PPG, ACCX, ACCY and ACCZ datasets into sliding chunks of 8-seconds using specgram()\n",
    "- It then uses the frequency domain data returned by specgram()\n",
    "- All frequencies outside of the physiologically relevant band are weeded out.\n",
    "- The output is sorted on the spectral magnitude of the data and the top 3 frequencies are considered\n",
    "- Peaks of the Accelerometer Magnitude (L2 Norm) are also calculated\n",
    "\n",
    "If the dominant PPG peak does not coincide with the first, second or third peaks of ACCX, ACCY, ACCZ and ACC Magnitude, \n",
    "that is chosen as the predicted heart rate. Else, we move to the second dominant PPG peak and see if it coincides \n",
    "with the top 3 peaks of the accelerometer component signals. If not, that is chosen as the predicted heart rate. \n",
    "Else, the third dominant PPG peak is chosen as the predicted heart rate.\n",
    "\n",
    "This is compared with the ground truth and the error vector is calculated.\n",
    "\n",
    "Next, we calculate a degree of confidence and the error vectors of the samples that have the bottom 10% SNR\n",
    "are weeded out.\n",
    "\n",
    "The mean of the residual error vector is calculated as the final result.\n",
    "\n",
    "Experiments to improve accuracy and ensuing observations:\n",
    "    1/ I am checking variance of the PPG peaks with the accelerometer component signal peaks (accx, accy, accz) \n",
    "       as well as  with the accelerometer magnitude (L2Norm) peaks. However the accelerometer magnitude peaks \n",
    "       do not seem to have any additional bearing on improving the accuracy of results.\n",
    "    2/ Without the help of the accelerometer, the error more than doubles. As more peaks from accelerometer data is\n",
    "       leveraged, the error progressively reduces. For example, if only the first peak is considered from accx/accy/accz,\n",
    "       the manifested error is about 20% more than if the first and second peaks are considered.\n",
    "    3/ 90th percentile calculation with the fundamental frequency alone (without harmonics) is yielding same results as\n",
    "       expanding the spectral band to include both the fundamental frequency band and the first harmonic. In other words\n",
    "       considering the harmonic is not making a difference to the final result\n",
    "    4/ If allowed to increase the tolerated confidence level, the error is showing a downward trend. For example,\n",
    "       if only samples greater than an 80% confidence level are chosen (instead of 90%), the error rate comes down\n",
    "       by about 5%. However, since the question asks for only the bottom 10% to be weeded out, I have let it at that\n",
    "       level.\n",
    "    5/ I have tried various values of width of the band around the peak to calculate the SNR. I have currently set it to\n",
    "       the width to 0.25 HZ\n",
    "    6/ I have also tried tuning min_freq and max_freq. A reduction of max_freq to 200 BPM or 3.3 HZ (rather than 240 BPM) \n",
    "       brings significant improvement to the accuracy. I do understand the trade-offs, but I have let the max at 3.3 HZ.\n",
    "       I assume that if a patient's heart beat is detected close to 200 BPM, the patient is likely to be red-flagged \n",
    "       for more tests.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Next Steps\n",
    "You will now go to **Test Your Algorithm** to apply a unit test to confirm that your algorithm met the success criteria. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
